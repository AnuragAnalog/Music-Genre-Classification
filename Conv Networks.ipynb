{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e54bd21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 14:30:13.206208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-12 14:30:13.296304: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/openmpi-4.1.2-4a/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/tcl-8.6.11-d4/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/sqlite-3.37.1-6s/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/zlib-1.2.11-2y/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib64:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib\n",
      "2024-04-12 14:30:13.296344: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-12 14:30:14.714920: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/openmpi-4.1.2-4a/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/tcl-8.6.11-d4/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/sqlite-3.37.1-6s/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/zlib-1.2.11-2y/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib64:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib\n",
      "2024-04-12 14:30:14.715022: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/openmpi-4.1.2-4a/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/tcl-8.6.11-d4/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/sqlite-3.37.1-6s/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/zlib-1.2.11-2y/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib64:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib\n",
      "2024-04-12 14:30:14.715028: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Required modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477c855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 10 classes.\n",
      "Found 199 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of ImageDataGenerator for data augmentation (optional)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize the images\n",
    "#     rotation_range=20,  # Data augmentation: Random rotations\n",
    "#     width_shift_range=0.2,  # Data augmentation: Random horizontal shifts\n",
    "#     height_shift_range=0.2,  # Data augmentation: Random vertical shifts\n",
    "#     shear_range=0.2,  # Data augmentation: Random shearing\n",
    "#     zoom_range=0.2,  # Data augmentation: Random zooming\n",
    "    horizontal_flip=True,  # Data augmentation: Random horizontal flips\n",
    "    fill_mode='nearest',  # Strategy for filling in newly created pixels\n",
    "    validation_split=0.2  # Splitting the data: 80% for training, 20% for validation\n",
    ")\n",
    "\n",
    "# Assuming your dataset directory is \"/path/to/dataset\"\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './Data/images_original/',\n",
    "    target_size=(432, 288),  # Resize images to 150x150\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # For multi-class classification\n",
    "    subset='training'  # Specify this is training data\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    './Data/images_original/',\n",
    "    target_size=(432, 288),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Specify this is validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79a33898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 14:30:16.928441: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/openmpi-4.1.2-4a/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/tcl-8.6.11-d4/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/sqlite-3.37.1-6s/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/zlib-1.2.11-2y/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib64:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib\n",
      "2024-04-12 14:30:16.928481: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-04-12 14:30:16.928507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (amd002.orc.gmu.edu): /proc/driver/nvidia/version does not exist\n",
      "2024-04-12 14:30:16.928883: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# A 3 layer Conv model\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(432, 288, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')  # 10 classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3982400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "optims = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c91c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 47s 2s/step - loss: 3.9647 - accuracy: 0.1175 - val_loss: 2.2226 - val_accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 47s 2s/step - loss: 2.1474 - accuracy: 0.2163 - val_loss: 2.0106 - val_accuracy: 0.2292\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 46s 2s/step - loss: 1.8319 - accuracy: 0.3688 - val_loss: 1.7282 - val_accuracy: 0.3854\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 47s 2s/step - loss: 1.5477 - accuracy: 0.4313 - val_loss: 1.5682 - val_accuracy: 0.4375\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 47s 2s/step - loss: 1.3083 - accuracy: 0.5263 - val_loss: 1.5511 - val_accuracy: 0.4844\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 47s 2s/step - loss: 1.1356 - accuracy: 0.6162 - val_loss: 1.4669 - val_accuracy: 0.5052\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.9507 - accuracy: 0.6625 - val_loss: 1.5841 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.7291 - accuracy: 0.7750 - val_loss: 1.4149 - val_accuracy: 0.5417\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.6344 - accuracy: 0.8000 - val_loss: 1.5347 - val_accuracy: 0.5156\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.5279 - accuracy: 0.8338 - val_loss: 1.5978 - val_accuracy: 0.5469\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.3855 - accuracy: 0.8700 - val_loss: 1.7466 - val_accuracy: 0.5417\n",
      "Epoch 12/50\n",
      "16/25 [==================>...........] - ETA: 21s - loss: 0.3262 - accuracy: 0.8906"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7362a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "val_loss, val_acc = model.evaluate(validation_generator)\n",
    "print(f'Validation loss: {val_loss}, Validation accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd9bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cars",
   "language": "python",
   "name": "cars"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
