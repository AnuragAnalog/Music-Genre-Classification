{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e54bd21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 17:53:47.646060: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-10 17:53:48.267210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/openmpi-4.1.2-4a/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/tcl-8.6.11-d4/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/sqlite-3.37.1-6s/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/zlib-1.2.11-2y/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib64:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib\n",
      "2024-04-10 17:53:48.267238: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-10 17:53:52.609986: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/openmpi-4.1.2-4a/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/tcl-8.6.11-d4/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/sqlite-3.37.1-6s/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/zlib-1.2.11-2y/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib64:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib\n",
      "2024-04-10 17:53:52.612364: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/openmpi-4.1.2-4a/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/tcl-8.6.11-d4/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/sqlite-3.37.1-6s/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/zlib-1.2.11-2y/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib64:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib\n",
      "2024-04-10 17:53:52.612380: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Required modules\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pyts\n",
    "import wave\n",
    "import glob\n",
    "import tqdm\n",
    "import keras\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.signal as sps\n",
    "import plotly.express as px\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyts.classification import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5739467a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>...</td>\n",
       "      <td>52.420910</td>\n",
       "      <td>-1.690215</td>\n",
       "      <td>36.524071</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>41.597103</td>\n",
       "      <td>-2.303523</td>\n",
       "      <td>55.062923</td>\n",
       "      <td>1.221291</td>\n",
       "      <td>46.936035</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>...</td>\n",
       "      <td>55.356403</td>\n",
       "      <td>-0.731125</td>\n",
       "      <td>60.314529</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>48.120598</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>51.106190</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>45.786282</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>...</td>\n",
       "      <td>40.598766</td>\n",
       "      <td>-7.729093</td>\n",
       "      <td>47.639427</td>\n",
       "      <td>-1.816407</td>\n",
       "      <td>52.382141</td>\n",
       "      <td>-3.439720</td>\n",
       "      <td>46.639660</td>\n",
       "      <td>-2.231258</td>\n",
       "      <td>30.573025</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>...</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.319130</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>...</td>\n",
       "      <td>86.099236</td>\n",
       "      <td>-5.454034</td>\n",
       "      <td>75.269707</td>\n",
       "      <td>-0.916874</td>\n",
       "      <td>53.613918</td>\n",
       "      <td>-4.404827</td>\n",
       "      <td>62.910812</td>\n",
       "      <td>-11.703234</td>\n",
       "      <td>55.195160</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0  blues.00000.wav  661794          0.350088         0.088757  0.130228   \n",
       "1  blues.00001.wav  661794          0.340914         0.094980  0.095948   \n",
       "2  blues.00002.wav  661794          0.363637         0.085275  0.175570   \n",
       "3  blues.00003.wav  661794          0.404785         0.093999  0.141093   \n",
       "4  blues.00004.wav  661794          0.308526         0.087841  0.091529   \n",
       "\n",
       "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0  0.002827             1784.165850          129774.064525   \n",
       "1  0.002373             1530.176679          375850.073649   \n",
       "2  0.002746             1552.811865          156467.643368   \n",
       "3  0.006346             1070.106615          184355.942417   \n",
       "4  0.002303             1835.004266          343399.939274   \n",
       "\n",
       "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0              2002.449060            85882.761315  ...   52.420910   \n",
       "1              2039.036516           213843.755497  ...   55.356403   \n",
       "2              1747.702312            76254.192257  ...   40.598766   \n",
       "3              1596.412872           166441.494769  ...   44.427753   \n",
       "4              1748.172116            88445.209036  ...   86.099236   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "0    -1.690215   36.524071    -0.408979   41.597103    -2.303523   55.062923   \n",
       "1    -0.731125   60.314529     0.295073   48.120598    -0.283518   51.106190   \n",
       "2    -7.729093   47.639427    -1.816407   52.382141    -3.439720   46.639660   \n",
       "3    -3.319597   50.206673     0.636965   37.319130    -0.619121   37.259739   \n",
       "4    -5.454034   75.269707    -0.916874   53.613918    -4.404827   62.910812   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "0     1.221291   46.936035  blues  \n",
       "1     0.531217   45.786282  blues  \n",
       "2    -2.231258   30.573025  blues  \n",
       "3    -3.407448   31.949339  blues  \n",
       "4   -11.703234   55.195160  blues  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the 30 sec data features\n",
    "\n",
    "features30 = pd.read_csv(\"./Data/features_30_sec.csv\")\n",
    "features30.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e4343e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.0.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.335406</td>\n",
       "      <td>0.091048</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>1773.065032</td>\n",
       "      <td>167541.630869</td>\n",
       "      <td>1972.744388</td>\n",
       "      <td>117335.771563</td>\n",
       "      <td>...</td>\n",
       "      <td>39.687145</td>\n",
       "      <td>-3.241280</td>\n",
       "      <td>36.488243</td>\n",
       "      <td>0.722209</td>\n",
       "      <td>38.099152</td>\n",
       "      <td>-5.050335</td>\n",
       "      <td>33.618073</td>\n",
       "      <td>-0.243027</td>\n",
       "      <td>43.771767</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00000.1.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.343065</td>\n",
       "      <td>0.086147</td>\n",
       "      <td>0.112699</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>1816.693777</td>\n",
       "      <td>90525.690866</td>\n",
       "      <td>2010.051501</td>\n",
       "      <td>65671.875673</td>\n",
       "      <td>...</td>\n",
       "      <td>64.748276</td>\n",
       "      <td>-6.055294</td>\n",
       "      <td>40.677654</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>51.264091</td>\n",
       "      <td>-2.837699</td>\n",
       "      <td>97.030830</td>\n",
       "      <td>5.784063</td>\n",
       "      <td>59.943081</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00000.2.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.346815</td>\n",
       "      <td>0.092243</td>\n",
       "      <td>0.132003</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>1788.539719</td>\n",
       "      <td>111407.437613</td>\n",
       "      <td>2084.565132</td>\n",
       "      <td>75124.921716</td>\n",
       "      <td>...</td>\n",
       "      <td>67.336563</td>\n",
       "      <td>-1.768610</td>\n",
       "      <td>28.348579</td>\n",
       "      <td>2.378768</td>\n",
       "      <td>45.717648</td>\n",
       "      <td>-1.938424</td>\n",
       "      <td>53.050835</td>\n",
       "      <td>2.517375</td>\n",
       "      <td>33.105122</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00000.3.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.132565</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>1655.289045</td>\n",
       "      <td>111952.284517</td>\n",
       "      <td>1960.039988</td>\n",
       "      <td>82913.639269</td>\n",
       "      <td>...</td>\n",
       "      <td>47.739452</td>\n",
       "      <td>-3.841155</td>\n",
       "      <td>28.337118</td>\n",
       "      <td>1.218588</td>\n",
       "      <td>34.770935</td>\n",
       "      <td>-3.580352</td>\n",
       "      <td>50.836224</td>\n",
       "      <td>3.630866</td>\n",
       "      <td>32.023678</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00000.4.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.143289</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>1630.656199</td>\n",
       "      <td>79667.267654</td>\n",
       "      <td>1948.503884</td>\n",
       "      <td>60204.020268</td>\n",
       "      <td>...</td>\n",
       "      <td>30.336359</td>\n",
       "      <td>0.664582</td>\n",
       "      <td>45.880913</td>\n",
       "      <td>1.689446</td>\n",
       "      <td>51.363583</td>\n",
       "      <td>-3.392489</td>\n",
       "      <td>26.738789</td>\n",
       "      <td>0.536961</td>\n",
       "      <td>29.146694</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0  blues.00000.0.wav   66149          0.335406         0.091048  0.130405   \n",
       "1  blues.00000.1.wav   66149          0.343065         0.086147  0.112699   \n",
       "2  blues.00000.2.wav   66149          0.346815         0.092243  0.132003   \n",
       "3  blues.00000.3.wav   66149          0.363639         0.086856  0.132565   \n",
       "4  blues.00000.4.wav   66149          0.335579         0.088129  0.143289   \n",
       "\n",
       "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0  0.003521             1773.065032          167541.630869   \n",
       "1  0.001450             1816.693777           90525.690866   \n",
       "2  0.004620             1788.539719          111407.437613   \n",
       "3  0.002448             1655.289045          111952.284517   \n",
       "4  0.001701             1630.656199           79667.267654   \n",
       "\n",
       "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0              1972.744388           117335.771563  ...   39.687145   \n",
       "1              2010.051501            65671.875673  ...   64.748276   \n",
       "2              2084.565132            75124.921716  ...   67.336563   \n",
       "3              1960.039988            82913.639269  ...   47.739452   \n",
       "4              1948.503884            60204.020268  ...   30.336359   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "0    -3.241280   36.488243     0.722209   38.099152    -5.050335   33.618073   \n",
       "1    -6.055294   40.677654     0.159015   51.264091    -2.837699   97.030830   \n",
       "2    -1.768610   28.348579     2.378768   45.717648    -1.938424   53.050835   \n",
       "3    -3.841155   28.337118     1.218588   34.770935    -3.580352   50.836224   \n",
       "4     0.664582   45.880913     1.689446   51.363583    -3.392489   26.738789   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "0    -0.243027   43.771767  blues  \n",
       "1     5.784063   59.943081  blues  \n",
       "2     2.517375   33.105122  blues  \n",
       "3     3.630866   32.023678  blues  \n",
       "4     0.536961   29.146694  blues  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the 3 sec data features\n",
    "\n",
    "features3 = pd.read_csv(\"./Data/features_3_sec.csv\")\n",
    "features3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34849718",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 22050\n",
    "new_rate = 2205\n",
    "window_size = int(3 * sr)\n",
    "hop_length = int(1 * sr)\n",
    "\n",
    "def segment_audio_files(data, window_size, hop_length, labels):\n",
    "    \"\"\"\n",
    "    Segments the audio data into fixed-size windows.\n",
    "    \n",
    "    :param data: Array of audio samples.\n",
    "    :param window_size: The number of samples in each window.\n",
    "    :param hop_length: The number of samples to slide the window by for the next segment.\n",
    "    :return: A list of segmented audio windows.\n",
    "    \"\"\"\n",
    "\n",
    "    segments = []\n",
    "    extended_labels = []\n",
    "    for sample, label in tqdm.tqdm(zip(data, labels)):\n",
    "        for start in range(0, len(sample) - window_size + 1, hop_length):\n",
    "            segment = sample[start:start + window_size]\n",
    "            number_of_samples = round(len(segment) * float(new_rate) / sr)\n",
    "            segments.append(sps.resample(segment, number_of_samples))\n",
    "            extended_labels.append(label)\n",
    "    return np.array(segments), extended_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "083836c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/genres_original/jazz/jazz.00054.wav file does not start with RIFF id\n"
     ]
    }
   ],
   "source": [
    "all_music = list()\n",
    "labels = list()\n",
    "\n",
    "for dir_name in os.listdir(\"./Data/genres_original/\"):\n",
    "    for fname in glob.glob(f\"./Data/genres_original/{dir_name}/*.wav\"):\n",
    "        try:\n",
    "            audio_data = np.frombuffer(wave.open(fname, \"r\").readframes(-1)[4:], dtype=np.int16)\n",
    "            number_of_samples = round(len(audio_data) * float(new_rate) / (sr*10))\n",
    "            all_music.append(sps.resample(audio_data, number_of_samples))\n",
    "#             all_music.append(audio_data)\n",
    "            labels.append(dir_name)\n",
    "        except Exception as e:\n",
    "            print(fname, e)\n",
    "\n",
    "# segmented_data, labels = segment_audio_files(all_music, window_size, hop_length, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d45d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train and test data\n",
    "\n",
    "X, y = pd.DataFrame(all_music), pd.DataFrame(labels)\n",
    "X.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7abde02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apeddi/.local/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/apeddi/.local/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1c07f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=88)\n",
    "y_train = pd.get_dummies(y_train).astype(np.int32)\n",
    "y_test = pd.get_dummies(y_test).astype(np.int32)\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a81c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifing the data\n",
    "\n",
    "X_train = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0eaa73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 17:55:03.772277: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/openmpi-4.1.2-4a/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/tcl-8.6.11-d4/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/sqlite-3.37.1-6s/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/zlib-1.2.11-2y/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib64:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib\n",
      "2024-04-10 17:55:03.772307: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-04-10 17:55:03.772369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (amd003.orc.gmu.edu): /proc/driver/nvidia/version does not exist\n",
      "2024-04-10 17:55:03.774514: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "def make_model(input_shape):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.Flatten()(conv3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(10, activation=\"softmax\")(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=X_train.shape[1:])\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38e14104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1028, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1122, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 691, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/metrics/metrics.py\", line 3669, in sparse_categorical_accuracy\n        matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 962, in sparse_categorical_matches\n        y_true = tf.squeeze(y_true, [-1])\n\n    ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](Cast_43)' with input shapes: [?,10].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     14\u001b[0m ]\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     16\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file42i01ydl.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1028, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1122, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 691, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/metrics/metrics.py\", line 3669, in sparse_categorical_accuracy\n        matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"/home/apeddi/.local/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 962, in sparse_categorical_matches\n        y_true = tf.squeeze(y_true, [-1])\n\n    ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](Cast_43)' with input shapes: [?,10].\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.keras\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train.values,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27edeeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"best_model.keras\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Test accuracy\", test_acc)\n",
    "print(\"Test loss\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d555c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the history, which has Accuracy and Loss\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab27f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features\n",
    "\n",
    "def extract_features(file_path):\n",
    "    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast') \n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "     \n",
    "    return mfccs_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72c5b9c",
   "metadata": {},
   "source": [
    "## CNNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2352dd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 10 classes.\n",
      "Found 199 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of ImageDataGenerator for data augmentation (optional)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize the images\n",
    "#     rotation_range=20,  # Data augmentation: Random rotations\n",
    "#     width_shift_range=0.2,  # Data augmentation: Random horizontal shifts\n",
    "#     height_shift_range=0.2,  # Data augmentation: Random vertical shifts\n",
    "#     shear_range=0.2,  # Data augmentation: Random shearing\n",
    "#     zoom_range=0.2,  # Data augmentation: Random zooming\n",
    "#     horizontal_flip=True,  # Data augmentation: Random horizontal flips\n",
    "#     fill_mode='nearest',  # Strategy for filling in newly created pixels\n",
    "    validation_split=0.2  # Splitting the data: 80% for training, 20% for validation\n",
    ")\n",
    "\n",
    "# Assuming your dataset directory is \"/path/to/dataset\"\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './Data/images_original/',\n",
    "    target_size=(150, 150),  # Resize images to 150x150\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # For multi-class classification\n",
    "    subset='training'  # Specify this is training data\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    './Data/images_original/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Specify this is validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2a8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "423it [03:29,  3.33it/s]                       "
     ]
    }
   ],
   "source": [
    "train_imgs, valid_imgs = list(), list()\n",
    "train_labels, valid_labels = list(), list()\n",
    "\n",
    "for x, y in tqdm.tqdm(train_generator):\n",
    "    train_imgs.extend(x.tolist())\n",
    "    train_labels.extend(y.tolist())\n",
    "print(\"Training Done\")\n",
    "\n",
    "for x, y in tqdm.tqdm(validation_generator):\n",
    "    valid_imgs.extend(x.tolist())\n",
    "    valid_labels.extend(y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0200e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list()\n",
    "valid = list()\n",
    "\n",
    "for t in train_generator.filenames:\n",
    "    fn = (f\"{t.split('/')[1].split('.')[0][:-5]}.{t.split('/')[1].split('.')[0][-5:]}.wav\")\n",
    "    train.append(features30[features30[\"filename\"] == fn].values[0][2:-1])\n",
    "    \n",
    "for t in validation_generator.filenames:\n",
    "    fn = (f\"{t.split('/')[1].split('.')[0][:-5]}.{t.split('/')[1].split('.')[0][-5:]}.wav\")\n",
    "    valid.append(features30[features30[\"filename\"] == fn].values[0][2:-1])\n",
    "    \n",
    "train, valid = np.array(train), np.array(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2d81711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# Image branch\n",
    "input_image = Input(shape=(150, 150, 3))\n",
    "x1 = Conv2D(32, (3, 3), activation='relu')(input_image)\n",
    "x1 = MaxPooling2D(2, 2)(x1)\n",
    "x1 = Conv2D(64, (3, 3), activation='relu')(x1)\n",
    "x1 = MaxPooling2D(2, 2)(x1)\n",
    "x1 = Conv2D(128, (3, 3), activation='relu')(x1)\n",
    "x1 = MaxPooling2D(2, 2)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "# Additional features branch\n",
    "input_features = Input(shape=(57,))\n",
    "x2 = Dense(128, activation='relu')(input_features)\n",
    "x2 = Dropout(0.5)(x2)\n",
    "x2 = BatchNormalization()(x2)  # Optional, helps to stabilize learning\n",
    "\n",
    "# Merge branches\n",
    "combined = concatenate([x1, x2])\n",
    "\n",
    "# Fully connected layers\n",
    "x = Dense(512, activation='relu')(combined)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(10, activation='softmax')(x)  # Assuming 10 classes\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input_image, input_features], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8f3bb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "355efbf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'keras.preprocessing.image.DirectoryIterator'>\", \"<class 'numpy.ndarray'>\"}), <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [121]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/data_adapter.py:1081\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1078\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle input: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1083\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1084\u001b[0m         )\n\u001b[1;32m   1085\u001b[0m     )\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1088\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1089\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1091\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'keras.preprocessing.image.DirectoryIterator'>\", \"<class 'numpy.ndarray'>\"}), <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [train_generator, train],\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=[validation_generator, valid],\n",
    "    validation_steps=validation_generator.n // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "63a599bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 211ms/step - loss: 1.5053 - accuracy: 0.4774\n",
      "Validation loss: 1.5053174495697021, Validation accuracy: 0.4773869216442108\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "val_loss, val_acc = model.evaluate(validation_generator)\n",
    "print(f'Validation loss: {val_loss}, Validation accuracy: {val_acc}')\n",
    "\n",
    "# Save the model\n",
    "model.save('path/to/save/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c91c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cars",
   "language": "python",
   "name": "cars"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
